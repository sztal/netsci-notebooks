{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cabb7e-5eb4-4ba9-8daf-540883303647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "# !pip install numpy pandas matplotlib python-igraph>=0.10.4\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# IGraph configuration\n",
    "# Set configuration variables\n",
    "ig.config[\"plotting.backend\"] = \"matplotlib\"  # use Matplotlib as plotting backend\n",
    "ig.config[\"plotting.vertex_color\"] = \"white\"\n",
    "ig.config[\"plotting.vertex_size\"] = \"0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb34bb7-ed8a-445b-86d0-e6231ef3ea30",
   "metadata": {},
   "source": [
    "# Fundamental generative models\n",
    "\n",
    "Generative network models are, in essence, mathematical models (often parametrized) that define probability distributions over networks\n",
    "of a given size (number of nodes), such that typical networks sampled from a given distribution tend to have some specific statistical-stuctural\n",
    "properties.\n",
    "\n",
    "Here we will review few models that were fundamental for early years of network science.\n",
    "\n",
    "## Types of generative models\n",
    "\n",
    "Here we will consider only so-called equilibrium models which assume fixed number of nodes. There are also more dynamic (non-equilibrium) models that\n",
    "represent systems that may grow or shrink in time \n",
    "(or evolve in other fundamental ways that change the sample space, that is, the set of possible networks that can be sampled). \n",
    "Interestingly, the two families of models are closely linked to either equilibrium and non-equilibrium statistical physics.\n",
    "\n",
    "**NOTE.**\n",
    "\n",
    "There are also dynamic equilibrium models, in which the adjacency structure (whom connects to whom) may change in time, but the point is\n",
    "that the system size stays the same. They belong to the first family of static/equilibrium models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db732c98-336b-4c71-98b4-8ec7675df8c9",
   "metadata": {},
   "source": [
    "## Erd≈ës-Renyi model\n",
    "\n",
    "Here we study the classical ER model, or more concretely its $G(n, p)$ variant, where $n$ is the number of nodes and $p$ is  the connection probability.\n",
    "Note that, assuming that we want to generate simple graphs, the expected node degree is:\n",
    "\n",
    "$$\n",
    "\\bar{d} = \\bar{d}_i = \\sum_{j \\neq i}^n p = p(n-1)\n",
    "$$\n",
    "\n",
    "Thus, $p$ can be mapped one-to-one to $\\bar{d}$, which means that (once $n$ is fixed) all properties of the model are determined by the average\n",
    "node degree, which is therefore its **control parameter**.\n",
    "\n",
    "This is useful, because its easier to interpret $\\bar{d}$ than $p$. We will use this perspective now to understand why most networks are well connected.\n",
    "\n",
    "### Emergence of connectedness in undirected graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ec830-5fd0-4f74-a875-60c2a9909db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 10000                          # number of nodes\n",
    "D = np.arange(.1, 5.5, .3)         # average degrees\n",
    "R = 10                             # number of repetitions\n",
    "F = np.empty_like(D, dtype=float)  # array for storing fractions of nodes in giant component\n",
    "V = np.empty(R, dtype=float)       # array for storing replication results (F)\n",
    "\n",
    "for i, dbar in enumerate(D):\n",
    "    for j in range(R):\n",
    "        p = dbar / (n-1)                                # determine p parameter as a function of dbar\n",
    "        G = ig.Graph.Erdos_Renyi(n, p, directed=False)  # initialize graph object\n",
    "        giant = G.components().giant()                  # extract giant component\n",
    "        frac = giant.vcount() / G.vcount()              # calculate fraction of nodes in the giant component\n",
    "        V[j] = frac\n",
    "    F[i] = V.mean()   # average results over 'R' replications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046496b-ce78-42af-be89-803ae5c6362f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ax.plot(D, F, marker=\"o\", ls=\"--\")\n",
    "ax.axvline(1, ls=\"--\", color=\"gray\")\n",
    "ax.set_xlabel(r\"$\\bar{d}$\")\n",
    "_ = ax.set_ylabel(\"Relative size of the giant component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca6236-b8a5-42f9-bf55-9aa7d5bf68cb",
   "metadata": {},
   "source": [
    "Let us see what happens a little bit more visually based on smaller networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04650ac-372f-46f6-bc37-9bed099eaf8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(303) # IGraph uses Python standard pseudorandom generator\n",
    "\n",
    "n = 100\n",
    "D = np.array([.1, .5, 1, 1.5, 2, 3])\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(D), figsize=(len(D)*5, 5))\n",
    "\n",
    "for ax, dbar in zip(axes.flat, D):\n",
    "    p = dbar / (n-1)\n",
    "    G = ig.Graph.Erdos_Renyi(n, p, directed=False)\n",
    "    giant = G.components().giant()\n",
    "    frac = giant.vcount() / G.vcount()\n",
    "    ig.plot(G, target=ax)\n",
    "    ax.set_title(rf\"$\\bar{{d}} = {dbar:.2f}, f = {frac:.3}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d555b44-b259-4312-9cdb-288cd83e0755",
   "metadata": {},
   "source": [
    "The critical value of $\\bar{d} = 1$ defines a **percolation threshold** of the system. This name points to the connection between the\n",
    "emergence of connectedness in random graphs and the physical process of **percolation**, that is, the movement of particles through porous\n",
    "materials. This is a very general idea that can be used, for instance, to model forest fires.\n",
    "\n",
    "**Question.**\n",
    "\n",
    "Do you see why percolation is connected to forest fires? (we will study this in more detail later)\n",
    "\n",
    "### Connectedness and sparsity\n",
    "\n",
    "Note that $\\bar{d} = p(n-1) \\Longrightarrow p = \\bar{d}/(n-1)$. In other words, when $\\bar{d}$ is held fixed, $p$ goes to zero as we increase $n$.\n",
    "Since $\\bar{d}$ is the sole controll parameter determining the percolation threshold, it means that percolation can be reached for abitrarily small\n",
    "values of $p$ if the system is large enough. So connectedness is possible, and in fact almost guaranteed, even in sparse systems.\n",
    "\n",
    "This is why **real networks are connected** (roughly).\n",
    "\n",
    "### Average shortest paths\n",
    "\n",
    "It is also instructive to see how average shortest paths scale with the system size in ER graphs above the percolation threshold.\n",
    "We will see that:\n",
    "\n",
    "$$L \\propto \\log{n}$$\n",
    "\n",
    "In other words, in random graphs average shortest paths scale proportionally to the logarithm of the number of nodes,\n",
    "which means they grow very slowly with the system size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47b14e-7795-4043-9178-5a764da5b9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = np.array([16, 32, 64, 128, 256, 512, 1024, 2048, 4096])  # numbers of nodes\n",
    "L = np.empty_like(N, dtype=float)                            # array for storing average path lengths\n",
    "dbar = 4                                                     # average degree\n",
    "R = 5                                                        # number of repetitions\n",
    "V = np.empty(5, dtype=float)                                 # array for storing L repetitions\n",
    "\n",
    "for i, n in enumerate(N):\n",
    "    p = dbar/(n-1)\n",
    "    for j in range(R):\n",
    "        G = ig.Graph.Erdos_Renyi(n, p, directed=False)\n",
    "        V[j] = G.average_path_length()\n",
    "    L[i] = V.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c8aec-75ca-4a7d-86e2-e06050b60098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "for ax, log in zip(axes.flat, [False, True]):\n",
    "    ax.plot(N, L, marker=\"o\", ls=\"--\")\n",
    "    if log:\n",
    "        ax.set_xscale(\"log\", base=2)\n",
    "        ax.set_title(\"Log scale\")\n",
    "    else:\n",
    "        ax.set_title(\"Natural scale\")\n",
    "\n",
    "fig.supxlabel(\"Number of nodes\")\n",
    "fig.supylabel(\"Average shortest path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbfb738-cf29-4110-8fd4-a933eeeb87f5",
   "metadata": {},
   "source": [
    "### Percolation in directed random graphs\n",
    "\n",
    "Now we consider percolation in directed graphs. In this case the situation is slightly more complex since we have two distinct notions\n",
    "of components.\n",
    "\n",
    "* **Strongly connected component.** Each node is connected to any other node by a directed path.\n",
    "* **Weakly connected component.** Each node is connected to any other node by a semipath (i.e. ignoring edge directions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e529ad0-cae9-4954-88f5-f7c916667e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = ig.Graph(directed=True)\n",
    "G.add_vertices(6)\n",
    "G.add_edges([\n",
    "    (0, 1),\n",
    "    (1, 2),\n",
    "    (2, 0),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 3),\n",
    "    (0, 3)\n",
    "])\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "for ax, mode in zip(axes.flat, [\"weak\", \"strong\"]):\n",
    "    comps = G.components(mode=mode)\n",
    "    ig.plot(G, mark_groups=comps, target=ax, edge_arrow_size=.02)\n",
    "    ax.set_title(f\"{mode.title()}ly connected components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf972f18-fa9c-48a5-b7b5-f9bfef05ad0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 10000                          # number of nodes\n",
    "D = np.arange(.1, 5.5, .3)         # average degrees\n",
    "R = 10                             # number of repetitions\n",
    "W = np.empty_like(D, dtype=float)  # array for storing fractions of nodes in weakly connected giant component\n",
    "S = np.empty_like(D, dtype=float)  # array for storing fractions of nodes in strongly connected giant component\n",
    "V = np.empty((R, 2), dtype=float)  # array for storing replication results (F)\n",
    "\n",
    "for i, dbar in enumerate(D):\n",
    "    for j in range(R):\n",
    "        p = dbar / (n-1)                                # determine p parameter as a function of dbar\n",
    "        G = ig.Graph.Erdos_Renyi(n, p, directed=True)   # initialize graph object (directed)\n",
    "        V[j, 0] = G.components(\"weak\").giant().vcount() / n\n",
    "        V[j, 1] = G.components(\"strong\").giant().vcount() / n\n",
    "    W[i] = V[:, 0].mean()  \n",
    "    S[i] = V[:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49685f41-e399-4972-89b8-21804cf9f073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "style = dict(marker=\"o\", ls=\"--\")\n",
    "ax.plot(D, W, **style, color=\"dodgerblue\", label=\"weak\")\n",
    "ax.plot(D, S, **style, color=\"indianred\", label=\"strong\")\n",
    "ax.set_xlabel(r\"$\\bar{d}$\")\n",
    "ax.set_ylabel(\"Relative giant component size\")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c7effa-aaa4-4511-a02d-7c92108c097a",
   "metadata": {},
   "source": [
    "Clearly, strong percolation happens later than weak percolation but again at $\\bar{d} = 1$, while weak percolation happens at roughly\n",
    "$\\bar{d} = 1/2$.\n",
    "\n",
    "**Question.**\n",
    "\n",
    "Do you know why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955b96d-051c-4a62-ba88-edde3588d7c4",
   "metadata": {},
   "source": [
    "## Random geometric graphs and locality principle\n",
    "\n",
    "In ER graphs connections are scattered randomly across the whole system. This presupposes that nodes possess a kind of **global knowledge**\n",
    "about the system **when establishing connections**. (This point is even clearer when we consider a process in which new nodes arrive\n",
    "and link to existing nodes at random.)\n",
    "\n",
    "Such an assumption may not be very reasonable in some contexts. So how can we conceive of a graph in which connections are trully localized?\n",
    "\n",
    "There are many ways to do this, but probably a simplest model is given by **Random Geometric Graphs** (RGG).\n",
    "\n",
    "In the the most classical RGG variant $n$ nodes are scattered uniformly at random over a unit square\n",
    "(perhaps wrapped as a torus, so it does not have boundaries) and then nodes which are at a distance\n",
    "$r$ or lower are connected. Here, $r$ is the control parameter which fully determines the properties\n",
    "of the induced ensemble of graphs.\n",
    "\n",
    "**NOTE.**\n",
    "\n",
    "Ensemble of graphs is a fany term for a specific probability distribution over graphs.\n",
    "\n",
    "**SIDE NOTE.**\n",
    "\n",
    "Many real systems, from social to brain networks, share many properties with random geometric graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2326782-957c-4f1e-af90-02bf707a3bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = ig.Graph.GRG(200, radius=.1, torus=False)\n",
    "ig.plot(G, vertex_color=\"red\", vertex_size=.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18ce34-67bb-44e3-8157-a0c75dc9adb7",
   "metadata": {},
   "source": [
    "Note that if we assume toroidal embedding (so no boundary) it is easy to get an exact expression for the expected average node degree\n",
    "in an RGG. Since nodes are distributed uniformly at random over the unit square, it is enough to consider the relative area of a unit\n",
    "circle of radius $r$ to the area of a unit square (which is equal to $1$). Thus, we have that:\n",
    "\n",
    "$$\n",
    "\\bar{d} = \\frac{\\pi{}r^2}{1}(n-1) = \\pi{}r^2(n-1)\n",
    "$$\n",
    "\n",
    "Hence, to get the radius producing a desired average degree we consider:\n",
    "\n",
    "$$\n",
    "r = \\sqrt{\\frac{\\bar{d}}{\\pi{}(n-1)}} \n",
    "$$\n",
    "\n",
    "So, we see that we can quite easily controll the basic properties of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc59ecf-1fe7-4d68-bb2b-74db4d6a7517",
   "metadata": {},
   "source": [
    "### Percolation, clustering and average path lengths in random geometric graphs\n",
    "\n",
    "Clearly, the locality principle encoded in RGGs enforces some degree of transitvity of relations leading, perhaps, to non-trivial\n",
    "levels of clustering. But how does it affect percolation and average path lengths?\n",
    "\n",
    "Note that conditional on nodes' positions the RGG model is fully deterministic, so we are now in a regime very different from ER random graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e809f0-e581-4311-84fd-4b5f2d30abb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 10000                          # number of nodes\n",
    "D = np.arange(.5, 8, .5)           # average degrees\n",
    "R = 10                             # number of repetitions\n",
    "C = np.empty_like(D, dtype=float)  # array for storing clustering coefficients\n",
    "F = np.empty_like(C)               # array for storing fractions of nodes in giant component\n",
    "V = np.empty((R, 2), dtype=float)  # array for storing replication results (F)\n",
    "\n",
    "for i, dbar in enumerate(D):\n",
    "    for j in range(R):\n",
    "        r = np.sqrt(dbar / (np.pi*(n-1)))                     # determine connection radius\n",
    "        G = ig.Graph.GRG(n, r, torus=True)                    # we use toroidal model to avoid boundary effects\n",
    "        clust = G.transitivity_undirected()                   # global clustering\n",
    "        frac  = G.components().giant().vcount() / G.vcount()  # fraction in giant component\n",
    "        V[j, 0] = clust\n",
    "        V[j, 1] = frac\n",
    "    C[i] = V[:, 0].mean()\n",
    "    F[i] = V[:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd47fc4-1a21-4586-b423-827b7ba303c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "style = dict(marker=\"o\", ls=\"--\")\n",
    "ax.plot(D, F, **style, color=\"dodgerblue\", label=\"giant component size\")\n",
    "ax.plot(D, C, **style, color=\"indianred\", label=\"clustering\")\n",
    "ax.axvline(1, ls=\"--\", color=\"gray\")\n",
    "ax.set_xlabel(r\"$\\bar{d}$\")\n",
    "_ = ax.set_ylabel(\"Relative size of the giant component\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839f21d-cc6a-462b-844a-ea5e942a21f4",
   "metadata": {},
   "source": [
    "We see that in this model clustering is (at least for some range of $r$ parameter values) is independent of average degree \n",
    "(and therefore also edge density) as well as percolation. This is a non-trivial results, because it shows that:\n",
    "\n",
    "* Percolation and connectedness is possible also in purely localized systems.\n",
    "* Localized systems with high clustering can be sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291182c7-5046-4803-9e8c-bc49241e6830",
   "metadata": {},
   "source": [
    "### Problem.\n",
    "\n",
    "Show that RGG is a good model of forest fire (or spatial percolation more generally). \n",
    "To this purpose, draw RGG graphs with 200 nodes and increasing radii such that some are below\n",
    "the percolation threshold and some above.\n",
    "\n",
    "**NOTE.**\n",
    "\n",
    "`Graph.GRG` instances comes with `x` and `y` attributes defined on vertices. They are used automatically by `igraph` for plotting,\n",
    "so you do not need to worry about positioning the nodes.\n",
    "\n",
    "**HINT.**\n",
    "\n",
    "Try repurposing the code from the chunk above as well as the earlier code we used to show percolation on small ER random graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70495d09-7d20-49a8-a054-91ab66e3f3ab",
   "metadata": {},
   "source": [
    "### Problem.\n",
    "\n",
    "Provide a code-based demonstration of the small-world effect using RGG model.\n",
    "Namely, show the evolution of clustering coefficient (global or average local)\n",
    "and average shortest path in RGG graphs of different sizes with different probabilities\n",
    "of edge rewiring.\n",
    "\n",
    "**HINT.**\n",
    "\n",
    "Try to use `.rewire_edges` method defined on graph objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f8cf8-5ca6-4fa4-a5c8-27f2ab672744",
   "metadata": {},
   "source": [
    "## Preferential attachment\n",
    "\n",
    "Now we turn to the famous **Preferential Attachment** (PA) model, which provides one of several good explanations for the ubiquitousness\n",
    "of right-skewed degree distributions.\n",
    "\n",
    "### Degree distributions in ER and RGG models\n",
    "\n",
    "But first let us note that degree distributions produced by ER and RGG models that we considered so far binomial and roughly symmetric.\n",
    "This is why we need tools like PA model, because otherwise we would not be able to understand the origins of heavy-tailed degree distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c8972-4885-4203-bd3d-88e9a0ebdfe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n    = 10000\n",
    "dbar = 10 \n",
    "\n",
    "graphs = {\n",
    "    \"ER\":  ig.Graph.Erdos_Renyi(n, p=dbar/(n-1)),\n",
    "    \"RGG\": ig.Graph.GRG(n, radius=np.sqrt(dbar/(np.pi*(n-1))), torus=True)\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "\n",
    "for ax, name in zip(axes.flat, graphs):\n",
    "    graph = graphs[name]\n",
    "    ax.hist(graph.degree(), edgecolor=\"black\")\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0af692-33e4-4302-b8db-7302ba7bf236",
   "metadata": {},
   "source": [
    "### Degree distribution in PA model\n",
    "\n",
    "Below we demonstrate the PA model and how it evolves towards right-skewed distributions.\n",
    "\n",
    "Remember that it is governed by the following dynamics:\n",
    "\n",
    "1. Start with an arbitrary graph.\n",
    "2. Create new node. It links to $m$ existing nodes with probabilities proportional to their degrees.\n",
    "3. Repeat (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c857b62-304b-4797-97ce-c8cbb3f9e91a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n  = 20 \n",
    "m1 = 2\n",
    "# Seed graph\n",
    "G  = ig.Graph.Erdos_Renyi(n, p=5/(n-1), directed=False)\n",
    "\n",
    "waves = [50, 100, 350, 500, 1000]\n",
    "graphs = [G]\n",
    "\n",
    "for n_nodes in np.cumsum(waves):\n",
    "    n_edges = np.random.randint(1, m1+1, n_nodes)\n",
    "    new = ig.Graph.Barabasi(n_nodes, m=1, directed=False, start_from=graphs[-1])\n",
    "    graphs.append(new)\n",
    "\n",
    "layout = graphs[-1].layout_kamada_kawai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b5a97-b040-4280-9f59-acf78cc001ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(graphs), ncols=2, figsize=(10, 5*len(graphs)))\n",
    "\n",
    "for axrow, graph in zip(axes, graphs):\n",
    "    ax = axrow[0]\n",
    "    ig.plot(graph, layout=layout[:graph.vcount()], target=ax, vertex_size=1)\n",
    "    ax.set_title(rf\"$N = {graph.vcount()}$\")\n",
    "    ax = axrow[1]\n",
    "    D = pd.Series(graph.degree()) # get degree sequence\n",
    "    C = D.value_counts()          # count occurence of unique values\n",
    "    P = C / C.sum()               # calculate probability distribution\n",
    "    \n",
    "    # Plot probability distribution in log-log scale\n",
    "    ax.scatter(P.index, P)\n",
    "    ax.set_xscale(\"log\", base=2)\n",
    "    ax.set_yscale(\"log\", base=2)\n",
    "    ax.set_xlabel(\"Node degree\")\n",
    "    ax.set_ylabel(\"Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c5f6c-40f6-42ea-b419-9263fdccf9b6",
   "metadata": {},
   "source": [
    "## Where does complexity come from?\n",
    "\n",
    "Now we are ready to make an attempt at understanding what it means for a network to be complex.\n",
    "As we have seen, some of the salient features of networks emerge from randomness, while some other\n",
    "arise as consequences of strict deterministic rules. And since real-world complex networks tend\n",
    "to have feature characteristic for both randomness and deterministic structuration, it must be\n",
    "that complexity arises from a dialectical interaction between this two seemingly opposed forces.\n",
    "\n",
    "We will now work through a simple example of data generating process based on mixing structured\n",
    "patterns with noise, which will produce networks with some of the salient features.\n",
    "The idea is generate two networks by overlaying RGG and PA networks as layers, then combine\n",
    "the two networks and finally inject some noise to connect the two otherwise disconnected\n",
    "components and ensure properties specific for random graphs (e.g. small path lengths).\n",
    "\n",
    "* **RGG** component is responsible for producing small scale localized structures\n",
    "  yielding non-trivial clustering (transitivity of relations),\n",
    "* **PA** component provides more right-skewed degree distribution endowing the network\n",
    "  with some structural hierarchy (some nodes are much better connected and important than others).\n",
    "* **Random** component ensure short path lengths and connectedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491af5ce-b0c1-4aff-a202-e7f9a4973dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_subgraph(n, dbar, m=1, label=\"\"):\n",
    "    \"\"\"Function for making a graph composed of RGG and PA layers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n\n",
    "        Number of nodes.\n",
    "    dbar\n",
    "        Expected average degree of the RGG layer.\n",
    "    m\n",
    "        Edge per new node in the PA layer.\n",
    "    label\n",
    "        Label used for naming graph.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    graph\n",
    "        Graph with RGG and PA layers combined.\n",
    "    rgg\n",
    "        RGG graph.\n",
    "    pa\n",
    "        PA graph.\n",
    "    \"\"\"\n",
    "    rgg = ig.Graph.GRG(n, radius=np.sqrt(dbar/(np.pi*(n-1))))\n",
    "    if isinstance(m, tuple):\n",
    "        m0, m1 = m\n",
    "        m = list(np.random.randint(m0, m1+1, n))\n",
    "    pa  = ig.Graph.Barabasi(n, m=m, directed=False)\n",
    "    graph = ig.union([rgg, pa])\n",
    "    del graph.vs[\"x\"]\n",
    "    del graph.vs[\"y\"]\n",
    "    graph.vs[\"name\"] = [ f\"{label}{vid}\" for vid in graph.vs.indices ]\n",
    "    graph.vs[\"group\"] = label\n",
    "    return graph, rgg, pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c03694-6f8f-4f7b-bdb6-29cba5e749b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(303)\n",
    "np.random.seed(304)\n",
    "\n",
    "sub1, rgg1, pa1 = make_subgraph(1000, 5, m=(1, 2), label=\"a\")\n",
    "sub2, rgg2, pa2 = make_subgraph(1000, 3, m=(1, 3), label=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee5600-05d3-4ce0-8268-d3f7bbb496e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10, 10))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ig.plot(rgg1, target=ax, vertex_size=.02)\n",
    "ax.set_title(\"Subgraph I, RGG layer\")\n",
    "ax = axes[0, 1]\n",
    "ig.plot(pa1, target=ax, vertex_size=1, edge_width=.1)\n",
    "ax.set_title(\"Subgraph I, PA layer\")\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ig.plot(rgg2, target=ax, vertex_size=.02)\n",
    "ax.set_title(\"Subgraph II, RGG layer\")\n",
    "ax = axes[1, 1]\n",
    "ig.plot(pa2, target=ax, vertex_size=1, edge_width=.1)\n",
    "_ = ax.set_title(\"Subgraph II, PA layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961d2d7-e29f-48f9-9cb0-6be04d8116c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Combine subgraphs\n",
    "G = ig.union([sub1, sub2])\n",
    "\n",
    "## Add noise by rewiring edges\n",
    "## We use a rewiring algorithm that does not\n",
    "## change the degree sequence.\n",
    "G.rewire(int(.1*G.ecount()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8768cbf-4a0d-4618-8e2e-6fce54526d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "D = np.array(G.degree())\n",
    "_ = plt.hist(D, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698740c9-df18-4b68-9687-770bd10651b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ig.plot(G, target=ax, vertex_size=.5*np.sqrt(D), edge_width=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57861f-1c36-4210-a569-8b4d85f3bfd7",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "Analyze the structure of the network we just created.\n",
    "\n",
    "1. Calculate clustering coefficient (global and/or average local). How does it compare to edge density?\n",
    "2. Plot average local clustering coefficients grouped by node degrees. How do you interpret the pattern you see?\n",
    "3. Use `.assortativity_degree` to calculate Pearson correlation between degrees of connected nodes. What does the value tell you about preferences of nodes?\n",
    "4. Check the documentation of `.assortativity_nominal` method. Use to calculate assortativity with respect to `.vs[\"group\"]` vertex attribute.\n",
    "   What does the value tell you about the extent to which the injected noise destroyed the information about the two original subgraphs?\n",
    "5. Re-plot the graph and color nodes by their betweeness (using `.betweenness` method). Where do you find nodes with highest values\n",
    "   and what does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7739e20-ae9b-490b-bdec-10bb34bc388d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
